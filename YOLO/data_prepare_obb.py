import os
import json
import shutil
import random
from pathlib import Path

import pandas as pd
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon

"""
Prepare a dataset for Ultralytics YOLO Oriented Bounding‐Box (OBB) models.

The script expects a CSV generated by **Label Studio** with the following columns:
    • image_path – absolute *or* path relative to ``source_img_dir``
    • bbox        – JSON list with entries that contain ``x``, ``y``, ``width``, ``height`` (percentages 0-100)
    • label       – high-level label "Fracture" | "Normal"

For rows tagged as "Fracture" every bounding box is converted to the YOLO OBB text
format: ``class_id x1 y1 x2 y2 x3 y3 x4 y4`` where the 4 corners are **normalised
between 0–1** (as required by Ultralytics – see docs: https://docs.ultralytics.com/datasets/obb/).

Images labelled "Normal" are copied without any bounding boxes (empty ``.txt`` file).

Directory layout produced::

    dest_root/
        images/
            train/ …
            val/   …
            test/  …
        labels/
            train/ …  # *.txt in YOLO OBB format
            val/   …
            test/  …
        classes.txt   # names line-by-line
        data.yaml     # Ultralytics dataset YAML
        validation_samples_obb.png  # optional quick visual check
"""

# ---------------------------------------------------------------------------
# USER CONFIGURATION
# ---------------------------------------------------------------------------
csv_path = "/home/ai-user/efficientdet/Combined_filtered_stripped.csv"
source_img_dir = "/home/ai-user/data"
dest_root = "/home/ai-user/efficientdet/YOLO/data_anklel_obb"

# Dataset split ratios (train / test / val must sum to 1)
train_ratio = 0.84
test_ratio = 0.01
val_ratio = 0.15

# Detection classes (Fracture is the only object class; Normal images carry no objects)
classes = ["Fracture", "Normal"]
# ---------------------------------------------------------------------------

# Create required directories ------------------------------------------------------------------
for split in ["train", "test", "val"]:
    Path(dest_root, "images", split).mkdir(parents=True, exist_ok=True)
    Path(dest_root, "labels", split).mkdir(parents=True, exist_ok=True)

# Write classes.txt so Ultralytics HUB/GUIDES can map indices back to names --------------------
with open(Path(dest_root, "classes.txt"), "w") as f:
    for cls in classes:
        f.write(f"{cls}\n")

class_mapping = {cls: idx for idx, cls in enumerate(classes)}


def convert_row_to_obb(row: pd.Series, img_dir: str):
    """Return list[str] of YOLO OBB annotations and relative image path."""
    raw_path = row["image_path"]
    image_path = raw_path if os.path.isabs(raw_path) else os.path.join(img_dir, raw_path)
    rel_image_path = os.path.relpath(image_path, start=img_dir)

    # Attempt to read bounding-box JSON --------------------------------------------------------
    bbox_str = row.get("bbox")
    if pd.isna(bbox_str):
        return [], rel_image_path  # no boxes
    try:
        bbox_data = json.loads(bbox_str)
    except (json.JSONDecodeError, TypeError):
        return [], rel_image_path
    if not isinstance(bbox_data, list):
        return [], rel_image_path

    # Only keep boxes for rows explicitly labelled as "Fracture" ------------------------------
    if str(row.get("label", "")).strip().lower() != "fracture":
        return [], rel_image_path

    annotations = []
    for box in bbox_data:
        # Label Studio stores x,y,width,height as **percentages (0-100)** of the image dims
        x_pct, y_pct, w_pct, h_pct = box["x"], box["y"], box["width"], box["height"]

        # Derive four axis-aligned corners (top-left, top-right, bottom-right, bottom-left)
        x1 = x_pct / 100.0
        y1 = y_pct / 100.0
        x2 = (x_pct + w_pct) / 100.0
        y2 = y1
        x3 = x2
        y3 = (y_pct + h_pct) / 100.0
        x4 = x1
        y4 = y3

        class_id = class_mapping["Fracture"]
        annotations.append(f"{class_id} {x1} {y1} {x2} {y2} {x3} {y3} {x4} {y4}")
    return annotations, rel_image_path


# Read CSV and build a list of dicts ------------------------------------------------------------
df = pd.read_csv(csv_path)

data_records = []
for _, row in df.iterrows():
    yolo_anns, rel_path = convert_row_to_obb(row, source_img_dir)
    data_records.append({
        "image_path": row["image_path"],  # keep original reference
        "rel_path": rel_path,
        "annotations": yolo_anns,
    })

# Split the dataset ---------------------------------------------------------------------------
train_data, temp_data = train_test_split(data_records, test_size=(test_ratio + val_ratio), random_state=42)
val_fraction_of_temp = val_ratio / (test_ratio + val_ratio)
test_data, val_data = train_test_split(temp_data, test_size=val_fraction_of_temp, random_state=42)


# Helper for copying images & writing label files ---------------------------------------------

def process_split(split_data, split_name):
    for record in split_data:
        # Resolve absolute source image path ---------------------------------------------------
        src_img = record["image_path"] if os.path.isabs(record["image_path"]) else os.path.join(source_img_dir, record["image_path"])
        if not os.path.exists(src_img):
            print(f"[WARNING] Source image missing – skipped: {src_img}")
            continue

        dst_img = Path(dest_root, "images", split_name, record["rel_path"])
        dst_img.parent.mkdir(parents=True, exist_ok=True)
        # Copy only if it doesn't already exist (idempotent behaviour) ------------------------
        if not dst_img.exists():
            shutil.copy2(src_img, dst_img)

        # Write label file (mirrors image path, .txt extension) -------------------------------
        label_file = dst_img.with_suffix(".txt").as_posix().replace("/images/", "/labels/")
        Path(label_file).parent.mkdir(parents=True, exist_ok=True)
        with open(label_file, "w") as f:
            f.write("\n".join(record["annotations"]))


for name, split in [("train", train_data), ("test", test_data), ("val", val_data)]:
    process_split(split, name)

# Create Ultralytics data.yaml ----------------------------------------------------------------
yaml_content = f"""# Automatically generated for YOLO OBB training
path: {dest_root}

train: images/train
val: images/val
test: images/test

nc: {len(classes)}
names: {classes}
"""
with open(Path(dest_root, "data.yaml"), "w") as f:
    f.write(yaml_content)

print("\n✅ Dataset preparation complete:")
print(f"   Train images : {len(train_data)}")
print(f"   Val images   : {len(val_data)}")
print(f"   Test images  : {len(test_data)}")
print(f"   Destination  : {dest_root}\n")


# ---------------------------------------------------------------------------
# OPTIONAL QUICK VISUAL CHECK ------------------------------------------------
# ---------------------------------------------------------------------------

def quick_visualise(root: str, split: str = "train", num_samples: int = 5):
    img_dir = Path(root, "images", split)
    label_dir = Path(root, "labels", split)
    images = [p for p in img_dir.rglob("*") if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]
    if not images:
        print("No images found for visualisation.")
        return

    samples = random.sample(images, min(num_samples, len(images)))

    with open(Path(root, "classes.txt")) as f:
        class_names = [l.strip() for l in f.readlines()]

    plt.figure(figsize=(15, 15))
    for idx, img_path in enumerate(samples):
        img = Image.open(img_path)
        plt.subplot(2, 3, idx + 1)
        plt.imshow(img)
        plt.axis("off")

        label_path = Path(label_dir, img_path.relative_to(img_dir)).with_suffix(".txt")
        if label_path.exists():
            with open(label_path) as lf:
                for line in lf:
                    parts = line.strip().split()
                    if len(parts) != 9:
                        continue  # malformed
                    cls_id = int(parts[0])
                    coords = np.array(list(map(float, parts[1:])))
                    xs = coords[0::2] * img.width
                    ys = coords[1::2] * img.height
                    poly = Polygon(np.column_stack((xs, ys)), closed=True, edgecolor='r', fill=False, linewidth=2)
                    plt.gca().add_patch(poly)
                    plt.text(xs[0], ys[0]-5, class_names[cls_id], color='red', fontsize=8,
                             bbox=dict(facecolor='white', alpha=0.7))
    plt.tight_layout()
    vis_path = Path(root, "validation_samples_obb.png")
    plt.savefig(vis_path)
    plt.show()
    print(f"Visualisation saved to → {vis_path}")


# Uncomment to run a quick check after preparation --------------------------------------------
quick_visualise(dest_root, "train", num_samples=5) 